# ğŸŒ™ AMMA 2.0 - Bedtime Story Agent

**AMMA** (Adaptive Multi-agent Motherly Assistant) is an intelligent conversational AI system that creates personalized bedtime stories for children. Built with a hybrid architecture combining **ReAct (Reasoning and Acting)** and **Reflection** patterns, AMMA provides natural conversation while generating high-quality, safe bedtime stories.

![AMMA Architecture](https://github.com/user-attachments/assets/21c95737-c7f0-48ae-90c5-bf2cf0044db0)

*Multi-agent architecture combining ReAct for interaction and Reflection for story creation*

## ğŸ—ï¸ Architecture Overview

AMMA combines two powerful AI patterns to deliver both natural interaction and high-quality story generation:

### **ReAct Pattern (Interaction Layer)**
- **Purpose**: Natural conversation and preference collection
- **Agent**: AMMA conversational agent
- **Tools**: `update_story_preferences`, `request_new_story`
- **Flow**: Reason about user input â†’ Act with appropriate tools â†’ Respond naturally

### **Reflection Pattern (Story Creation Layer)**
- **Purpose**: High-quality story generation through iterative improvement
- **Agents**: Story Creator â†’ Story Evaluator â†’ Story Presenter
- **Flow**: Create story â†’ Evaluate quality â†’ Approve/Revise â†’ Present final story

## ğŸ¯ Agent Flow

```
User Input â†’ AMMA (Conversational) â†’ Tools â†’ Story Creator â†’ Story Evaluator
                â†“                                              â†“
             End Chat                                    Story Presenter
                                                              â†“
                                                         Final Story
                                                              â†“
                                                    Revision Handler (if needed)
```

### **Core Agents**
1. **ğŸ—£ï¸ AMMA (Conversational)**: Motherly interaction, preference collection, conversation management
2. **âœï¸ Story Creator**: Generates bedtime stories (5-10 min reading time, age 5-10)
3. **ğŸ” Story Evaluator**: Reviews for safety, tone, age-appropriateness, and bedtime suitability
4. **ğŸ“– Story Presenter**: Delivers clean, final story to user
5. **ğŸ”„ Revision Handler**: Manages story improvement iterations

### **State Management**
- Child information (name, preferences)
- Story content and revisions
- Conversation history
- Evaluation results and feedback
- Revision tracking (max 3 iterations)

## ğŸ“¦ Installation & Setup

### **Prerequisites**
- Python 3.11+ (for backend)
- Node.js 18+ (for frontend)  
- OpenAI API key
- Docker (optional, for containerized backend)

### **ğŸš€ Quick Setup**

**Option 1: One-Command Install (Recommended)**
```bash
# Install everything automatically
python install.py
```

**Option 2: Manual Setup**
```bash
# 1. Clone repository
git clone https://github.com/ksriyesh/AMMA-Your-Motherly-Storyteller.git
cd AMMA-Your-Motherly-Storyteller

# 2. Backend Setup
pip install -e .

# 3. Frontend Setup
cd AMMA-UI
npm install
cd ..

# 4. Environment Variables
echo "OPENAI_API_KEY=your_openai_key_here" > .env
```

### **ğŸ“‹ Package Installation Details**

**Backend Dependencies (Python):**
```bash
# Core packages installed via pyproject.toml:
pip install -e .

# Key dependencies:
# - langchain-core, langchain-openai (LLM integration)
# - langgraph (multi-agent orchestration) 
# - fastapi, uvicorn (web server)
# - websockets (real-time communication)
# - pydantic (data validation)
# - python-dotenv (environment management)
```

**Frontend Dependencies (Node.js):**
```bash
cd AMMA-UI
npm install

# Key dependencies:
# - next.js (React framework)
# - tailwindcss (styling)
# - shadcn/ui (UI components)
# - lucide-react (icons)
```

## ğŸ–¥ï¸ Local Development

### **Option 1: Full Stack Development**
```bash
# Start both backend and frontend
python start_app.py

# Access:
# Frontend: http://localhost:3000
# Backend: http://localhost:8001
# API Docs: http://localhost:8001/docs
```

### **Option 2: Separate Development**
```bash
# Terminal 1: Backend only
python -m uvicorn app:app --reload --port 8001

# Terminal 2: Frontend only
cd AMMA-UI
npm run dev

# Access:
# Frontend: http://localhost:3000
# Backend: http://localhost:8001
```

### **Option 3: CLI Testing**
```bash
# Simple command-line interface
python main.py

# Pure conversational interface - chat directly with AMMA
```

## ğŸ³ Docker Deployment

### **Backend Only (Production)**
```bash
# Build backend container
docker build -t amma-backend .

# Run with environment variables
docker run -p 8001:8080 \
  -e OPENAI_API_KEY=your_key_here \
  -e PORT=8080 \
  amma-backend

# Access:
# Backend: http://localhost:8001
# API Docs: http://localhost:8001/docs
```

### **Docker for Railway Deployment**
```bash
# The Dockerfile is optimized for Railway deployment
# Railway automatically:
# 1. Detects the Dockerfile
# 2. Sets PORT environment variable
# 3. Handles container orchestration

# For Railway:
# 1. Connect GitHub repo to Railway
# 2. Add OPENAI_API_KEY environment variable
# 3. Deploy automatically
```

## â˜ï¸ Production Deployment

### **Backend (Railway)**
1. **Connect Repository**: Link your GitHub repo to Railway
2. **Environment Variables**: Add `OPENAI_API_KEY` in Railway dashboard
3. **Auto-Deploy**: Railway detects `Dockerfile` and deploys automatically
4. **Access**: `https://your-service.railway.app`

### **Frontend (GitHub Pages)**  
1. **Enable GitHub Pages**: Repository Settings â†’ Pages â†’ Source: "GitHub Actions"
2. **Environment Variables**: Add in Repository Settings â†’ Actions â†’ Variables:
   ```
   NEXT_PUBLIC_API_URL = https://your-backend.railway.app
   NEXT_PUBLIC_WS_URL = wss://your-backend.railway.app/ws
   ```
3. **Auto-Deploy**: Frontend deploys automatically on push to main
4. **Access**: `https://yourusername.github.io/repository-name/`

### **Complete Production Setup**
- **Backend**: Railway (handles WebSocket connections, API, story generation)
- **Frontend**: GitHub Pages (static React app, global CDN)
- **Connection**: Frontend connects to Railway backend via WebSocket
- **Cost**: GitHub Pages (free), Railway (free tier available)

## ğŸ“ Project Structure

```
AMMA/
â”œâ”€â”€ ğŸš€ Backend (Railway Deployment)
â”‚   â”œâ”€â”€ src/amma/              # Core agent implementation
â”‚   â”‚   â”œâ”€â”€ graph.py          # Multi-agent orchestration
â”‚   â”‚   â”œâ”€â”€ prompts.py        # Agent system prompts
â”‚   â”‚   â”œâ”€â”€ state.py          # Pydantic state models
â”‚   â”‚   â”œâ”€â”€ tools.py          # ReAct tools
â”‚   â”‚   â””â”€â”€ utils.py          # Utilities
â”‚   â”œâ”€â”€ app.py                # FastAPI server + WebSocket
â”‚   â”œâ”€â”€ Dockerfile            # Container configuration
â”‚   â””â”€â”€ pyproject.toml        # Python dependencies
â”œâ”€â”€ ğŸ¨ Frontend (GitHub Pages)
â”‚   â””â”€â”€ AMMA-UI/              # Next.js React application
â”‚       â”œâ”€â”€ app/page.tsx      # Main chat interface
â”‚       â”œâ”€â”€ components/       # UI components
â”‚       â””â”€â”€ lib/              # Utilities
â”œâ”€â”€ ğŸ”§ Local Development
â”‚   â”œâ”€â”€ start_app.py          # Full-stack launcher
â”‚   â”œâ”€â”€ main.py              # CLI interface
â”‚   â””â”€â”€ install.py           # Dependency installer
â”œâ”€â”€ ğŸš€ Deployment
â”‚   â””â”€â”€ .github/workflows/    # GitHub Actions (frontend deployment)
â””â”€â”€ ğŸ“– Documentation
    â””â”€â”€ README.md
```

## ğŸš€ Usage Examples

### **CLI Interface**
```bash
python main.py
# ğŸŒ™ AMMA - Bedtime Story Agent
# Press Ctrl+C to exit
# 
# You: Hi AMMA
# AMMA: Hello dear! I'm AMMA, your motherly storyteller...
```

### **Web Interface**
```bash
python start_app.py
# Visit: http://localhost:3000
# Chat with AMMA in a beautiful web interface
```

### **API Usage**
```bash
curl -X POST "http://localhost:8001/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "Tell me a story about dragons", "session_id": "test123"}'
```

## ğŸ¯ Key Features

- **ğŸ¤– Multi-Agent Architecture**: ReAct + Reflection patterns
- **ğŸŒ™ Bedtime-Optimized**: Soothing tone, age-appropriate content
- **ğŸ”„ Story Revisions**: Iterative improvement based on user feedback
- **âš¡ Real-Time Streaming**: WebSocket-based chat interface
- **ğŸ›¡ï¸ Safety-First**: Built-in content evaluation and filtering
- **ğŸ“± Responsive UI**: Works on desktop and mobile
- **ğŸ³ Production-Ready**: Docker + Railway + GitHub Pages deployment
- **ğŸ”§ Developer-Friendly**: Local development tools and CLI interface

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **LangChain**: For LLM integration and agent framework
- **LangGraph**: For multi-agent orchestration
- **OpenAI**: For GPT models powering story generation
- **FastAPI**: For high-performance web API
- **Next.js**: For modern React framework
- **Railway**: For seamless backend deployment
- **GitHub Pages**: For free frontend hosting

---

*Built with â¤ï¸ for creating magical bedtime experiences for children*
